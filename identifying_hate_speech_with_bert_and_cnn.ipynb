{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019-12-02-identifying-hate-speech-with-bert-and-cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "baS0lOejtaxT"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tZkP2rutt1O",
        "outputId": "9e7c9618-19c5-4e4e-b207-4436169820e5"
      },
      "source": [
        "# !pip uninstall transformers\r\n",
        "!pip install transformers==3.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==3.5 in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.9.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (20.9)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5) (1.19.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5) (1.24.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5) (53.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5) (1.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJPwpokJtaxZ"
      },
      "source": [
        "import logging\n",
        "import time\n",
        "from platform import python_version\n",
        "import random\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformers\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZxwPGvGtaxa",
        "outputId": "a6a2649d-4157-48f3-9794-528f50aac37f"
      },
      "source": [
        "print(\"python version==%s\" % python_version())\n",
        "print(\"pandas==%s\" % pd.__version__)\n",
        "print(\"numpy==%s\" % np.__version__)\n",
        "print(\"torch==%s\" % torch.__version__)\n",
        "print(\"sklearn==%s\" % sklearn.__version__)\n",
        "print(\"transformers==%s\" % transformers.__version__)\n",
        "print(\"matplotlib==%s\" % matplotlib.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python version==3.6.9\n",
            "pandas==1.1.5\n",
            "numpy==1.19.5\n",
            "torch==1.7.0+cu101\n",
            "sklearn==0.22.2.post1\n",
            "transformers==3.5.0\n",
            "matplotlib==3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SudIBKt5taxb"
      },
      "source": [
        "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtcSv5btyeMQ",
        "outputId": "9054e7ec-26bd-4697-e5b8-160919a9d742"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM-sdDENtaxb",
        "outputId": "71155c55-081d-4574-971e-d8768dbcaecf"
      },
      "source": [
        "# df = pd.read_csv('drive/MyDrive/train.csv')\n",
        "df = pd.read_csv('drive/MyDrive/reviews.csv')\n",
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(358957, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVGzuCVa6gQ5"
      },
      "source": [
        "random_seed = 42\r\n",
        "\r\n",
        "torch.manual_seed(random_seed)\r\n",
        "torch.cuda.manual_seed(random_seed)\r\n",
        "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\r\n",
        "# torch.backends.cudnn.deterministic = True\r\n",
        "torch.backends.cudnn.benchmark = False\r\n",
        "np.random.seed(random_seed)\r\n",
        "random.seed(random_seed)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hid6Pjketaxc"
      },
      "source": [
        "df = df.sample(frac=1)\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "YgSAZVfntaxc",
        "outputId": "506542fa-36ec-4168-a9bd-3c539e953014"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>prod_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>label</th>\n",
              "      <th>date</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58479</td>\n",
              "      <td>251</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-05-01</td>\n",
              "      <td>Went on a Friday night at about 5:30 PM, it wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>39714</td>\n",
              "      <td>202</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-10-26</td>\n",
              "      <td>Nice ambiance, very nice staff and good food. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>101723</td>\n",
              "      <td>523</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2013-11-17</td>\n",
              "      <td>we went to the city for a long weekend and rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33349</td>\n",
              "      <td>100</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-07-12</td>\n",
              "      <td>Foods tasted: Walnut french toast Blueberry pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>23432</td>\n",
              "      <td>305</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2014-12-16</td>\n",
              "      <td>LOVE the new space. It wasn't too overly packe...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  ...                                             review\n",
              "0    58479  ...  Went on a Friday night at about 5:30 PM, it wa...\n",
              "1    39714  ...  Nice ambiance, very nice staff and good food. ...\n",
              "2   101723  ...  we went to the city for a long weekend and rea...\n",
              "3    33349  ...  Foods tasted: Walnut french toast Blueberry pa...\n",
              "4    23432  ...  LOVE the new space. It wasn't too overly packe...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "6212LVvutaxc",
        "outputId": "8e934b40-9468-4a9f-b882-50e8ab8183f7"
      },
      "source": [
        "# df.comment_text[0]\r\n",
        "df.review[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Went on a Friday night at about 5:30 PM, it was still early and plenty of seats were available. \\xa0Its a very cool nondescript vibe in here, I liked it though. \\xa0For drinks I had the Penicillin and the Pomegranate Sour, the former was tart and sweet. It was the better of the two. \\xa0Husband had the pickle juice martini and that was really good. You really get like a nice mild pickle flavor as the drink finishes in your mouth. For food we just had a couple of appetizers: the hamachi with wasabi cream and soybeans and the pork buns. \\xa0Both were delicious especially the pork buns. \\xa0I doused them with a liberal amount of sircacha and it did not make it incredibly spicy. It just added to the richness of the flavors. \\xa0Very enjoyable cool place and I am looking forward to coming back here.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "_0evrdFjtaxd",
        "outputId": "0a7ec49c-00fa-4fb3-ada0-4957e9a37f3c"
      },
      "source": [
        "# target_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "# df.iloc[[103]][target_columns]\n",
        "\n",
        "target_columns = [\"label\"]\n",
        "df.iloc[[103]][target_columns]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     label\n",
              "103      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJkMwVEmtaxd"
      },
      "source": [
        "df_train = df[:10000].reset_index(drop=True)\n",
        "df_val = df[10000:11000].reset_index(drop=True)\n",
        "df_test = df[11000:13000].reset_index(drop=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAGS3i0ptaxd",
        "outputId": "1a8cec59-b503-4dec-9762-34edbe1c6c2b"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFCtHydMtaxe",
        "outputId": "b626266d-062d-431b-90b7-27dd57a17e04"
      },
      "source": [
        "df_val.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjjNhjnAtaxe",
        "outputId": "e4e69adb-66e0-486f-8095-d199617dd511"
      },
      "source": [
        "df_test.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NWLA7iltaxe"
      },
      "source": [
        "model_class = transformers.BertModel\n",
        "tokenizer_class = transformers.BertTokenizer\n",
        "pretrained_weights='bert-base-uncased'"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXkPd8T8taxe"
      },
      "source": [
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "bert_model = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Odjez8j8taxf"
      },
      "source": [
        "max_seq = 30"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lYAfvNytaxf"
      },
      "source": [
        "def tokenize_text(df, max_seq):\n",
        "    return [\n",
        "        # tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.comment_text.values\n",
        "        tokenizer.encode(text, add_special_tokens=True)[:max_seq] for text in df.review.values\n",
        "    ]\n",
        "\n",
        "\n",
        "def pad_text(tokenized_text, max_seq):\n",
        "    return np.array([el + [0] * (max_seq - len(el)) for el in tokenized_text])\n",
        "\n",
        "\n",
        "def tokenize_and_pad_text(df, max_seq):\n",
        "    tokenized_text = tokenize_text(df, max_seq)\n",
        "    padded_text = pad_text(tokenized_text, max_seq)\n",
        "    return torch.tensor(padded_text)\n",
        "\n",
        "\n",
        "def targets_to_tensor(df, target_columns):\n",
        "    return torch.tensor(df[target_columns].values, dtype=torch.float32)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3a0GDYbtaxf",
        "outputId": "cd9db09f-cf5a-4521-a308-d97f060f09d0"
      },
      "source": [
        "train_indices = tokenize_and_pad_text(df_train, max_seq)\n",
        "val_indices = tokenize_and_pad_text(df_val, max_seq)\n",
        "test_indices = tokenize_and_pad_text(df_test, max_seq)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (626 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvQOxhE7taxf"
      },
      "source": [
        "with torch.no_grad():\n",
        "    x_train = bert_model(train_indices)[0]  # Models outputs are tuples\n",
        "    x_val = bert_model(val_indices)[0]\n",
        "    x_test = bert_model(test_indices)[0]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ivf4pittaxf"
      },
      "source": [
        "y_train = targets_to_tensor(df_train, target_columns)\n",
        "y_val = targets_to_tensor(df_val, target_columns)\n",
        "y_test = targets_to_tensor(df_test, target_columns)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzimpV72taxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5271b6b0-0c30-4aad-acc8-28e49b5707c7"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.5355e-04, -5.9795e-02,  3.6013e-01,  ..., -9.4116e-01,\n",
              "          3.7106e-01, -2.4679e-01],\n",
              "        [-1.3350e-01, -3.6086e-01,  5.3668e-01,  ..., -9.7294e-01,\n",
              "          6.2427e-01, -7.6214e-02],\n",
              "        [-3.8279e-01, -5.6181e-01,  1.7381e-01,  ..., -7.2725e-01,\n",
              "          4.0075e-01,  7.8115e-02],\n",
              "        ...,\n",
              "        [ 2.4551e-01,  3.2521e-02,  3.9446e-01,  ..., -1.0495e+00,\n",
              "          2.9889e-01, -4.0031e-01],\n",
              "        [-9.9070e-02, -4.7349e-02,  5.2690e-01,  ..., -9.8018e-01,\n",
              "          3.9076e-01, -1.5049e-01],\n",
              "        [ 1.4652e-01, -1.9551e-01,  2.9518e-01,  ..., -1.1921e+00,\n",
              "          3.8039e-01, -1.9757e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnhOmVF2taxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a934fefc-4b41-41fa-e653-97777886bcc7"
      },
      "source": [
        "x_train[0].shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([30, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo_GSNWQtaxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f947f83-bfc9-4c55-96f1-02332d16cc2c"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOdWlEcEtaxg"
      },
      "source": [
        "class KimCNN(nn.Module):\n",
        "    def __init__(self, embed_num, embed_dim, class_num, kernel_num, kernel_sizes, dropout, static):\n",
        "        super(KimCNN, self).__init__()\n",
        "\n",
        "        V = embed_num\n",
        "        D = embed_dim\n",
        "        C = class_num\n",
        "        Co = kernel_num\n",
        "        Ks = kernel_sizes\n",
        "        \n",
        "        self.static = static\n",
        "        self.embed = nn.Embedding(V, D)\n",
        "        self.convs1 = nn.ModuleList([nn.Conv2d(1, Co, (K, D)) for K in Ks])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc1 = nn.Linear(len(Ks) * Co, C)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.static:\n",
        "            x = Variable(x)\n",
        "\n",
        "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
        "\n",
        "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
        "\n",
        "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
        "\n",
        "        x = torch.cat(x, 1)\n",
        "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
        "        logit = self.fc1(x)  # (N, C)\n",
        "        output = self.sigmoid(logit)\n",
        "        return output"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLhSZ4Hutaxh"
      },
      "source": [
        "embed_num = x_train.shape[1]\n",
        "embed_dim = x_train.shape[2]\n",
        "class_num = y_train.shape[1]\n",
        "kernel_num = 3\n",
        "kernel_sizes = [2, 3, 4]\n",
        "dropout = 0.5\n",
        "static = True"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYggZBmKtaxh"
      },
      "source": [
        "model = KimCNN(\n",
        "    embed_num=embed_num,\n",
        "    embed_dim=embed_dim,\n",
        "    class_num=class_num,\n",
        "    kernel_num=kernel_num,\n",
        "    kernel_sizes=kernel_sizes,\n",
        "    dropout=dropout,\n",
        "    static=static,\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZVrkfyntaxh"
      },
      "source": [
        "n_epochs = 10\n",
        "batch_size = 10\n",
        "lr = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvfRpc_-taxh"
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBAKAbWXtaxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f514b2ec-077e-496d-d30c-41d61c5474ea"
      },
      "source": [
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start_time = time.time()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train(True)\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_train, y_train, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    train_loss /= batch\n",
        "    train_losses.append(train_loss)\n",
        "    elapsed = time.time() - start_time\n",
        "\n",
        "    model.eval() # disable dropout for deterministic output\n",
        "    with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "        val_loss, batch = 0, 1\n",
        "        for x_batch, y_batch, batch in generate_batch_data(x_val, y_val, batch_size):\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            val_loss += loss.item()\n",
        "        val_loss /= batch\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        \"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\"\n",
        "        % (epoch + 1, train_losses[-1], val_losses[-1], elapsed)\n",
        "    )"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Train loss: 0.53. Validation loss: 0.54. Elapsed time: 17.01s.\n",
            "Epoch 2 Train loss: 0.51. Validation loss: 0.54. Elapsed time: 16.73s.\n",
            "Epoch 3 Train loss: 0.50. Validation loss: 0.55. Elapsed time: 16.90s.\n",
            "Epoch 4 Train loss: 0.49. Validation loss: 0.54. Elapsed time: 16.83s.\n",
            "Epoch 5 Train loss: 0.49. Validation loss: 0.54. Elapsed time: 16.70s.\n",
            "Epoch 6 Train loss: 0.48. Validation loss: 0.57. Elapsed time: 16.84s.\n",
            "Epoch 7 Train loss: 0.48. Validation loss: 0.55. Elapsed time: 16.95s.\n",
            "Epoch 8 Train loss: 0.47. Validation loss: 0.55. Elapsed time: 16.87s.\n",
            "Epoch 9 Train loss: 0.46. Validation loss: 0.55. Elapsed time: 16.76s.\n",
            "Epoch 10 Train loss: 0.46. Validation loss: 0.57. Elapsed time: 16.82s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jI4hTcstaxi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "b7259523-4257-4eee-d42a-35131e81aa0c"
      },
      "source": [
        "plt.plot(train_losses, label=\"Training loss\")\n",
        "plt.plot(val_losses, label=\"Validation loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Losses\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Losses')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kEK1KOYtaxi"
      },
      "source": [
        "model.eval() # disable dropout for deterministic output\n",
        "with torch.no_grad(): # deactivate autograd engine to reduce memory usage and speed up computations\n",
        "    y_preds = []\n",
        "    batch = 0\n",
        "    for x_batch, y_batch, batch in generate_batch_data(x_test, y_test, batch_size):\n",
        "        y_pred = model(x_batch)\n",
        "        y_preds.extend(y_pred.cpu().numpy().tolist())\n",
        "    y_preds_np = np.array(y_preds)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ8IiiPPtaxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e15e1f-7aba-4842-8534-e7a378698b96"
      },
      "source": [
        "y_preds_np"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.88402194],\n",
              "       [0.97084844],\n",
              "       [0.70481408],\n",
              "       ...,\n",
              "       [0.90974367],\n",
              "       [0.69465822],\n",
              "       [0.91142833]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61__k69taxj"
      },
      "source": [
        "y_test_np = df_test[target_columns].values"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78DMarKytaxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2219c78a-de78-4779-f5e1-5d745a0143e0"
      },
      "source": [
        "y_test_np[1000:]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [-1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1],\n",
              "       [ 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Y1RsYCtaxj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "6a20f893-8ac3-4978-c11b-4747bd1049b7"
      },
      "source": [
        "auc_scores = roc_auc_score(y_test_np, y_preds_np, average=None)\n",
        "df_accuracy = pd.DataFrame({\"label\": target_columns, \"auc\": auc_scores})\n",
        "df_accuracy.sort_values('auc')[::-1]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>label</td>\n",
              "      <td>0.556087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label       auc\n",
              "0  label  0.556087"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAtoUBd5taxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63fb5e38-f9ad-4058-c70a-6f4326ae7f76"
      },
      "source": [
        "positive_labels = df_train[target_columns].sum().sum()\n",
        "positive_labels"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7920"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okAqCy2Ttaxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4572b5-a5dd-4876-bd3d-d4f01d481455"
      },
      "source": [
        "all_labels = df_train[target_columns].count().sum()\n",
        "all_labels"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ystlx-fwtaxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78712a11-36ba-4391-bf5a-6fe3196930c3"
      },
      "source": [
        "positive_labels/all_labels"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4L9lLWataxn"
      },
      "source": [
        "df_test_targets = df_test[target_columns]\n",
        "df_pred_targets = pd.DataFrame(y_preds_np.round(), columns=target_columns, dtype=int)\n",
        "df_sanity = df_test_targets.join(df_pred_targets, how='inner', rsuffix='_pred')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6twDD6taxn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "aae50f32-4f11-431d-ec76-40683b577036"
      },
      "source": [
        "df_sanity"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  label_pred\n",
              "0         1           1\n",
              "1         1           1\n",
              "2         1           1\n",
              "3         1           1\n",
              "4         1           1\n",
              "...     ...         ...\n",
              "1995      1           1\n",
              "1996      1           1\n",
              "1997      1           1\n",
              "1998      1           1\n",
              "1999      1           1\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xcgUUU6taxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b4539a-a4a9-4060-b88e-369d6ed37682"
      },
      "source": [
        "df_test_targets.sum()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label    1564\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8iIjrJ7taxn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7680e60-9faf-440b-b1c5-e3e5bfae84f2"
      },
      "source": [
        "df_pred_targets.sum()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "label    1987\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onBm9ivCtaxo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "b88f760b-9ab8-4b57-da10-ceef48cb94b9"
      },
      "source": [
        "df_sanity[df_sanity.label > 0][['label', 'label_pred']]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>label_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1782 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  label_pred\n",
              "0         1           1\n",
              "1         1           1\n",
              "2         1           1\n",
              "3         1           1\n",
              "4         1           1\n",
              "...     ...         ...\n",
              "1995      1           1\n",
              "1996      1           1\n",
              "1997      1           1\n",
              "1998      1           1\n",
              "1999      1           1\n",
              "\n",
              "[1782 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lVPKtX2ArC6"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": []
    }
  ]
}